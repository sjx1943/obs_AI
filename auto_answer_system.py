import sqlite3
import pytesseract
import cv2
import subprocess
from flask import Flask, render_template_string, jsonify, request
from flask_cors import CORS
import threading
import time
import numpy as np
from datetime import datetime
import os
import json
from difflib import SequenceMatcher
import re
from PIL import Image, ImageEnhance
import jieba
import string

# Flaskåº”ç”¨é…ç½®
app = Flask(__name__)
CORS(app)
app.config['UPLOAD_FOLDER'] = '/tmp'  # ä¸´æ—¶å­˜å‚¨ä¸Šä¼ æ–‡ä»¶çš„ç›®å½•
app.config['ALLOWED_EXTENSIONS'] = {'csv'}

# å…¨å±€å˜é‡
current_ocr_text = ""  # å­˜å‚¨åŸå§‹OCRè¯†åˆ«ç»“æœ
current_qa_pairs = []  # å­˜å‚¨é¢˜ç›®-ç­”æ¡ˆå¯¹
current_questions = []  # ä¿æŒå…¼å®¹æ€§
current_answers = []   # ä¿æŒå…¼å®¹æ€§
last_qa_pairs = []
last_update_time = datetime.now()
is_running = False
frame_counter = 0
process_interval = 25  # å¤„ç†é—´éš”

# æ•°æ®åº“é…ç½®
DB_PATH = '/home/kennys/IdeaProjects/obs_AI/question_bank.db'

# å®Œæ•´çš„HTMLæ¨¡æ¿
HTML_TEMPLATE = '''
<!DOCTYPE html>
<html>
<head>
    <title>æ™ºèƒ½ç­”é¢˜åŠ©æ‰‹</title>
    <meta charset="utf-8">
    <style>
        body {
            font-family: 'Microsoft YaHei', Arial, sans-serif;
            margin: 0;
            padding: 15px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            height: 100vh;
            display: flex;
            flex-direction: column;
            font-size: 14px;
        }
        
        .container {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 20px;
            box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.37);
            border: 1px solid rgba(255, 255, 255, 0.18);
            flex: 1;
            display: flex;
            flex-direction: column;
            max-height: calc(100vh - 30px);
            overflow: hidden;
        }
        
        h1 {
            text-align: center;
            margin-bottom: 20px;
            font-size: 24px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        
        .status {
            text-align: center;
            margin-bottom: 15px;
            font-size: 13px;
            opacity: 0.9;
        }
        
        .stats {
            display: flex;
            justify-content: space-around;
            margin-bottom: 15px;
            font-size: 12px;
        }
        
        .stat-item {
            text-align: center;
        }
        
        .stat-number {
            font-size: 18px;
            font-weight: bold;
            color: #ffd700;
        }
        
        .ocr-raw-display {
            background: rgba(255, 255, 255, 0.15);
            border-radius: 10px;
            padding: 15px;
            margin-bottom: 15px;
            border-left: 4px solid #ff6b6b;
        }
        
        .ocr-label {
            font-weight: bold;
            color: #ffb3b3;
            margin-bottom: 8px;
            font-size: 14px;
            display: flex;
            align-items: center;
            justify-content: space-between;
        }
        
        .ocr-text {
            font-size: 14px;
            line-height: 1.6;
            white-space: pre-wrap;
            background: rgba(0, 0, 0, 0.2);
            padding: 10px;
            border-radius: 8px;
            font-family: 'Courier New', monospace;
            color: #ffffff;
            max-height: 150px;
            overflow-y: auto;
        }
        
        .qa-container {
            flex: 1;
            overflow-y: auto;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            padding: 15px;
            margin-bottom: 15px;
        }
        
        .qa-pair {
            background: rgba(255, 255, 255, 0.15);
            border-radius: 12px;
            padding: 20px;
            margin-bottom: 15px;
            border-left: 4px solid #ffd700;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            transition: transform 0.2s;
        }
        
        .qa-pair:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0,0,0,0.2);
        }
        
        .qa-pair.no-answer {
            border-left-color: #ff6b6b;
        }
        
        .qa-number {
            font-size: 16px;
            font-weight: bold;
            color: #ffd700;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
        }
        
        .qa-number::before {
            content: "ğŸ”";
            margin-right: 8px;
        }
        
        .question-text {
            font-size: 15px;
            line-height: 1.6;
            margin-bottom: 12px;
            color: #ffffff;
            background: rgba(255, 255, 255, 0.05);
            padding: 10px;
            border-radius: 8px;
            border-left: 3px solid #4fc3f7;
        }
        
        .answer-text {
            font-size: 15px;
            line-height: 1.6;
            color: #ffffff;
            background: rgba(76, 175, 80, 0.2);
            padding: 10px;
            border-radius: 8px;
            border-left: 3px solid #4caf50;
        }
        
        .answer-text.not-found {
            background: rgba(255, 152, 0, 0.2);
            border-left-color: #ff9800;
        }
        
        .question-label {
            font-weight: bold;
            color: #81d4fa;
            margin-bottom: 5px;
            font-size: 13px;
        }
        
        .answer-label {
            font-weight: bold;
            color: #a5d6a7;
            margin-bottom: 5px;
            font-size: 13px;
        }
        
        .answer-label.not-found {
            color: #ffcc02;
        }
        
        .no-data {
            text-align: center;
            opacity: 0.6;
            font-style: italic;
            padding: 40px;
            font-size: 16px;
        }
        
        .controls {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin-top: 15px;
        }
        
        button {
            background: rgba(255, 255, 255, 0.2);
            border: 1px solid rgba(255, 255, 255, 0.3);
            color: white;
            padding: 10px 20px;
            border-radius: 20px;
            cursor: pointer;
            font-size: 13px;
            transition: all 0.3s;
            font-family: 'Microsoft YaHei', sans-serif;
        }
        
        button:hover {
            background: rgba(255, 255, 255, 0.3);
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.2);
        }
        
        .status-indicator {
            display: inline-block;
            width: 8px;
            height: 8px;
            border-radius: 50%;
            margin-right: 8px;
            animation: pulse 2s infinite;
        }
        
        .status-running {
            background-color: #4ade80;
        }
        
        .status-stopped {
            background-color: #ef4444;
        }
        
        .update-time {
            font-size: 11px;
            opacity: 0.7;
            text-align: center;
            margin-top: 10px;
        }
        
        .match-confidence {
            font-size: 11px;
            opacity: 0.7;
            text-align: right;
            margin-top: 5px;
        }
        
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
        
        .search-info {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 8px;
            padding: 10px;
            margin-bottom: 15px;
            text-align: center;
            font-size: 12px;
            opacity: 0.8;
        }
        
        .toggle-btn {
            background: rgba(255, 255, 255, 0.15);
            border: none;
            color: white;
            padding: 5px 10px;
            border-radius: 15px;
            cursor: pointer;
            font-size: 11px;
            transition: all 0.3s;
        }
        
        .toggle-btn:hover {
            background: rgba(255, 255, 255, 0.25);
        }
        
        .collapsible {
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.3s ease;
        }
        
        .collapsible.expanded {
            max-height: 200px;
        }
        
        .debug-info {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 8px;
            padding: 10px;
            margin-bottom: 15px;
            font-size: 12px;
            opacity: 0.8;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ¯ æ™ºèƒ½ç­”é¢˜åŠ©æ‰‹</h1>
        <div class="status">
            <span class="status-indicator" id="statusIndicator"></span>
            <span id="statusText">ç­‰å¾…è¿æ¥...</span>
        </div>
        
        <div class="stats">
            <div class="stat-item">
                <div class="stat-number" id="questionCount">0</div>
                <div>è¯†åˆ«é¢˜ç›®</div>
            </div>
            <div class="stat-item">
                <div class="stat-number" id="answerCount">0</div>
                <div>åŒ¹é…ç­”æ¡ˆ</div>
            </div>
            <div class="stat-item">
                <div class="stat-number" id="successRate">0%</div>
                <div>æˆåŠŸç‡</div>
            </div>
        </div>
        
        <div class="search-info">
            <span>ğŸ“š æ”¯æŒä¸­è‹±æ–‡æ··åˆé¢˜ç›®åŒ¹é… | ğŸ” æ™ºèƒ½å…³é”®è¯æ£€ç´¢ | ğŸ’¡ æ¨¡ç³Šè¯­ä¹‰åŒ¹é…</span>
        </div>
        
        <!-- æ˜¾ç¤ºåŸå§‹OCRè¯†åˆ«ç»“æœ -->
        <div class="ocr-raw-display">
            <div class="ocr-label">
                <span>ğŸ” åŸå§‹OCRè¯†åˆ«ç»“æœï¼š</span>
                <button class="toggle-btn" onclick="toggleOCRDisplay()">å±•å¼€/æ”¶èµ·</button>
            </div>
            <div class="ocr-text collapsible expanded" id="ocrText">ç­‰å¾…OCRè¯†åˆ«...</div>
        </div>
        
        <!-- è°ƒè¯•ä¿¡æ¯ -->
        <div class="debug-info" id="debugInfo">
            è°ƒè¯•ä¿¡æ¯ï¼šç­‰å¾…å¤„ç†...
        </div>
        
        <div class="qa-container" id="qaContainer">
            <div class="no-data">ç­‰å¾…é¢˜ç›®è¯†åˆ«ä¸ç­”æ¡ˆåŒ¹é…...</div>
        </div>
        
        <div class="controls">
            <button onclick="toggleRecording()">
                <span id="recordingBtn">å¼€å§‹å½•åˆ¶</span>
            </button>
            <button onclick="clearDisplay()">æ¸…ç©ºæ˜¾ç¤º</button>
            <button onclick="exportResults()">å¯¼å‡ºç»“æœ</button>
            <button onclick="testOCR()">æµ‹è¯•OCR</button>
            <label class="button" style="background: rgba(255, 255, 255, 0.2); border: 1px solid rgba(255, 255, 255, 0.3); color: white; padding: 10px 20px; border-radius: 20px; cursor: pointer; font-size: 13px; transition: all 0.3s; font-family: 'Microsoft YaHei', sans-serif;">
                ä¸Šä¼ é¢˜åº“
                <input type="file" id="questionBankFile" accept=".csv" style="display: none;" onchange="uploadQuestionBank()">
            </label>
        </div>
        
        <div class="update-time" id="updateTime"></div>
    </div>
    
    <script>
        let isRunning = false;
        let ocrExpanded = true;
        
        function updateDisplay() {
            fetch('/get_results')
                .then(response => response.json())
                .then(data => {
                    updateOCRText(data.ocr_text);
                    updateQAPairs(data.qa_pairs);
                    updateStatus(data.is_running, data.last_update);
                    updateStats(data.qa_pairs);
                    updateDebugInfo(data.debug_info);
                })
                .catch(error => {
                    console.error('Error:', error);
                });
        }
        
        function updateOCRText(ocrText) {
            const ocrElement = document.getElementById('ocrText');
            if (ocrText && ocrText.trim()) {
                ocrElement.textContent = ocrText;
            } else {
                ocrElement.textContent = 'ç­‰å¾…OCRè¯†åˆ«...';
            }
        }
        
        function updateQAPairs(qaPairs) {
            const container = document.getElementById('qaContainer');
            if (qaPairs && qaPairs.length > 0) {
                container.innerHTML = qaPairs.map((pair, index) => {
                    const isNotFound = pair.answer === "æœªæ‰¾åˆ°ç­”æ¡ˆ" || pair.answer === "æœªåœ¨é¢˜åº“ä¸­æ‰¾åˆ°åŒ¹é…ç­”æ¡ˆ";
                    return `
                        <div class="qa-pair ${isNotFound ? 'no-answer' : ''}">
                            <div class="qa-number">ç¬¬ ${index + 1} é¢˜</div>
                            
                            <div class="question-label">ğŸ“ é¢˜ç›®ï¼š</div>
                            <div class="question-text">${pair.question}</div>
                            
                            <div class="answer-label ${isNotFound ? 'not-found' : ''}">
                                ${isNotFound ? 'âš ï¸ ç­”æ¡ˆï¼š' : 'ğŸ’¡ ç­”æ¡ˆï¼š'}
                            </div>
                            <div class="answer-text ${isNotFound ? 'not-found' : ''}">
                                ${pair.answer}
                            </div>
                            
                            ${pair.confidence ? `<div class="match-confidence">åŒ¹é…åº¦: ${pair.confidence}%</div>` : ''}
                        </div>
                    `;
                }).join('');
            } else {
                container.innerHTML = '<div class="no-data">ç­‰å¾…é¢˜ç›®è¯†åˆ«ä¸ç­”æ¡ˆåŒ¹é…...</div>';
            }
        }
        
        function updateStatus(running, lastUpdate) {
            const statusIndicator = document.getElementById('statusIndicator');
            const statusText = document.getElementById('statusText');
            const updateTime = document.getElementById('updateTime');
            const recordingBtn = document.getElementById('recordingBtn');
            
            isRunning = running;
            if (running) {
                statusIndicator.className = 'status-indicator status-running';
                statusText.textContent = 'ç³»ç»Ÿè¿è¡Œä¸­';
                recordingBtn.textContent = 'åœæ­¢å½•åˆ¶';
            } else {
                statusIndicator.className = 'status-indicator status-stopped';
                statusText.textContent = 'ç³»ç»Ÿå·²åœæ­¢';
                recordingBtn.textContent = 'å¼€å§‹å½•åˆ¶';
            }
            
            if (lastUpdate) {
                updateTime.textContent = 'æœ€åæ›´æ–°: ' + lastUpdate;
            }
        }
        
        function updateStats(qaPairs) {
            const questionCount = document.getElementById('questionCount');
            const answerCount = document.getElementById('answerCount');
            const successRate = document.getElementById('successRate');
            
            const qCount = qaPairs ? qaPairs.length : 0;
            const aCount = qaPairs ? qaPairs.filter(pair => 
                pair.answer !== "æœªæ‰¾åˆ°ç­”æ¡ˆ" && pair.answer !== "æœªåœ¨é¢˜åº“ä¸­æ‰¾åˆ°åŒ¹é…ç­”æ¡ˆ"
            ).length : 0;
            const rate = qCount > 0 ? Math.round((aCount / qCount) * 100) : 0;
            
            questionCount.textContent = qCount;
            answerCount.textContent = aCount;
            successRate.textContent = rate + '%';
        }
        
        function updateDebugInfo(debugInfo) {
            const debugElement = document.getElementById('debugInfo');
            if (debugInfo) {
                debugElement.textContent = debugInfo;
            } else {
                debugElement.textContent = 'è°ƒè¯•ä¿¡æ¯ï¼šç­‰å¾…å¤„ç†...';
            }
        }
    
       function uploadQuestionBank() {
                const fileInput = document.getElementById('questionBankFile');
                const file = fileInput.files[0];
                if (file) {
                    const formData = new FormData();
                    formData.append('file', file);
                    fetch('/upload_question_bank', {
                        method: 'POST',
                        body: formData
                    })
                    .then(response => response.json())
                    .then(data => {
                        if (data.success) {
                            alert('é¢˜åº“å¯¼å…¥æˆåŠŸ');
                        } else {
                            alert(`é¢˜åº“å¯¼å…¥å¤±è´¥: ${data.message}`);
                        }
                        fileInput.value = ''; // æ¸…ç©ºæ–‡ä»¶é€‰æ‹©
                    })
                    .catch(error => {
                        alert(`å‘ç”Ÿé”™è¯¯: ${error.message}`);
                    });
                }
            }
        
        function toggleRecording() {
            fetch('/toggle_recording', { method: 'POST' })
                .then(response => response.json())
                .then(data => {
                    console.log(data.message);
                });
        }
        
        function toggleOCRDisplay() {
            const ocrElement = document.getElementById('ocrText');
            if (ocrElement.classList.contains('expanded')) {
                ocrElement.classList.remove('expanded');
            } else {
                ocrElement.classList.add('expanded');
            }
        }
        
        function testOCR() {
            fetch('/test_ocr', { method: 'POST' })
                .then(response => response.json())
                .then(data => {
                    if (data.success) {
                        alert(`OCRæµ‹è¯•æˆåŠŸï¼è¯†åˆ«å‡º${data.question_count}ä¸ªé—®é¢˜`);
                    } else {
                        alert(`OCRæµ‹è¯•å¤±è´¥ï¼š${data.error}`);
                    }
                });
        }
        
        function clearDisplay() {
            fetch('/clear_display', { method: 'POST' })
                .then(response => response.json())
                .then(data => {
                    document.getElementById('qaContainer').innerHTML = '<div class="no-data">ç­‰å¾…é¢˜ç›®è¯†åˆ«ä¸ç­”æ¡ˆåŒ¹é…...</div>';
                });
        }
        
        function exportResults() {
            fetch('/export_results')
                .then(response => response.blob())
                .then(blob => {
                    const url = window.URL.createObjectURL(blob);
                    const a = document.createElement('a');
                    a.href = url;
                    a.download = 'answers_' + new Date().toISOString().slice(0,10) + '.txt';
                    a.click();
                    window.URL.revokeObjectURL(url);
                });
        }
        
        // æ¯ç§’æ›´æ–°ä¸€æ¬¡
        setInterval(updateDisplay, 1000);
        
        // é¡µé¢åŠ è½½æ—¶ç«‹å³æ›´æ–°
        updateDisplay();
    </script>
</body>
</html>
'''
# Flaskè·¯ç”±
@app.route('/')
def index():
    return render_template_string(HTML_TEMPLATE)

@app.route('/test_ocr', methods=['POST'])
def test_ocr():
    global current_ocr_text, current_qa_pairs, last_update_time

    try:
        # ä½¿ç”¨é™æ€æµ‹è¯•å›¾åƒ
        test_image_path = 'test_frame.png'
        if os.path.exists(test_image_path):
            img = cv2.imread(test_image_path)
            if img is None:
                return jsonify({"error": "æ— æ³•è¯»å–æµ‹è¯•å›¾åƒ"})

            # OCRè¯†åˆ«
            text = pytesseract.image_to_string(img, lang='chi_sim+eng')
            current_ocr_text = text

            # åˆ†å‰²é—®é¢˜
            questions = split_questions(text)

            # å¤„ç†æ¯ä¸ªé—®é¢˜
            qa_pairs = []
            for question in questions:
                if question and len(question) > 5:
                    answer, confidence = query_database_fuzzy(question)
                    qa_pairs.append({
                        'question': question,
                        'answer': answer,
                        'confidence': confidence if confidence > 0 else None
                    })

            current_qa_pairs = qa_pairs
            last_update_time = datetime.now()

            return jsonify({
                "success": True,
                "ocr_text": text,
                "question_count": len(questions)
            })
        else:
            return jsonify({"error": "æµ‹è¯•å›¾åƒä¸å­˜åœ¨"})
    except Exception as e:
        return jsonify({"error": str(e)})

@app.route('/upload_question_bank', methods=['POST'])
def upload_question_bank():
    if 'file' not in request.files:
        return jsonify({'success': False, 'message': 'æœªé€‰æ‹©æ–‡ä»¶'}), 400
    file = request.files['file']
    if file.filename == '':
        return jsonify({'success': False, 'message': 'æœªé€‰æ‹©æ–‡ä»¶'}), 400
    if file and allowed_file(file.filename):
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)
        file.save(file_path)
        success, message = import_question_bank(file_path)
        os.remove(file_path)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        return jsonify({'success': success, 'message': message})
    else:
        return jsonify({'success': False, 'message': 'åªå…è®¸ä¸Šä¼  CSV æ–‡ä»¶'}), 400

@app.route('/get_qa_pairs')
def get_qa_pairs():
    global current_qa_pairs, last_update_time, is_running
    return jsonify({
        "qa_pairs": current_qa_pairs,
        "last_update": last_update_time.strftime("%H:%M:%S"),
        "is_running": is_running
    })

@app.route('/toggle_recording', methods=['POST'])
def toggle_recording():
    global is_running
    is_running = not is_running
    if is_running:
        video_thread = threading.Thread(target=process_video_stream)
        video_thread.daemon = True
        video_thread.start()
        return jsonify({"message": "å½•åˆ¶å·²å¼€å§‹", "status": "running"})
    else:
        return jsonify({"message": "å½•åˆ¶å·²åœæ­¢", "status": "stopped"})

@app.route('/clear_display', methods=['POST'])
def clear_display():
    global current_qa_pairs, current_ocr_text, current_questions, current_answers
    current_qa_pairs = []
    current_ocr_text = ""
    current_questions = []
    current_answers = []
    return jsonify({"message": "æ˜¾ç¤ºå·²æ¸…ç©º"})

@app.route('/export_results')
def export_results():
    global current_qa_pairs
    content = f"æ™ºèƒ½ç­”é¢˜ç»“æœå¯¼å‡º\n{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
    content += "=" * 60 + "\n\n"

    for i, pair in enumerate(current_qa_pairs):
        content += f"ã€é¢˜ç›® {i+1}ã€‘\n"
        content += f"é—®é¢˜ï¼š{pair['question']}\n"
        content += f"ç­”æ¡ˆï¼š{pair['answer']}\n"
        if pair.get('confidence'):
            content += f"åŒ¹é…åº¦ï¼š{pair['confidence']}%\n"
        content += "\n" + "-" * 40 + "\n\n"

    from flask import make_response
    response = make_response(content)
    response.headers['Content-Type'] = 'text/plain; charset=utf-8'
    response.headers['Content-Disposition'] = 'attachment; filename=qa_results.txt'
    return response

@app.route('/get_results')
def get_results():
    global current_ocr_text, current_qa_pairs, is_running, last_update_time
    # æ„é€ è¿”å›çš„ JSON æ•°æ®
    response_data = {
        'ocr_text': current_ocr_text,
        'qa_pairs': current_qa_pairs,
        'is_running': is_running,
        'last_update': last_update_time.strftime('%Y-%m-%d %H:%M:%S'),
        'debug_info': ""  # å¯æ ¹æ®å®é™…éœ€æ±‚æ·»åŠ è°ƒè¯•ä¿¡æ¯
    }
    return jsonify(response_data)

# æ£€æŸ¥æ–‡ä»¶æ‰©å±•åæ˜¯å¦å…è®¸
def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']

# å¯¼å…¥é¢˜åº“å‡½æ•°ï¼ˆä¿ç•™æ­£ç¡®ç‰ˆæœ¬ï¼Œåˆ é™¤é‡å¤çš„åŒåå‡½æ•°ï¼‰
def import_question_bank(csv_file):
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    # ç»Ÿä¸€æ•°æ®åº“è¡¨åä¸º questionsï¼ˆä¸åç»­æŸ¥è¯¢é€»è¾‘ä¸€è‡´ï¼‰
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS questions (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            question TEXT NOT NULL UNIQUE,  -- æ·»åŠ  UNIQUE é¿å…é‡å¤
            answer TEXT NOT NULL
        )
    ''')
    try:
        inserted_count = 0
        with open(csv_file, 'r', encoding='utf-8') as f:
            import csv  # æ˜¾å¼å¯¼å…¥ csv æ¨¡å—ï¼ˆåŸä»£ç ä¸­æœ«å°¾å‡½æ•°ä½¿ç”¨äº† csv.readerï¼‰
            reader = csv.reader(f)
            for row in reader:
                if len(row) >= 2:  # å…¼å®¹ CSV å¯èƒ½çš„å¤šåˆ—æƒ…å†µ
                    question = row[0].strip()
                    answer = row[1].strip()
                    if question and answer:
                        # ä½¿ç”¨ INSERT OR IGNORE é¿å…é‡å¤å¯¼å…¥
                        cursor.execute('''
                            INSERT OR IGNORE INTO questions (question, answer)
                            VALUES (?, ?)
                        ''', (question, answer))
                        if cursor.rowcount > 0:
                            inserted_count += 1
        conn.commit()
        return True, f"æˆåŠŸå¯¼å…¥ {inserted_count} æ¡é¢˜ç›®"
    except Exception as e:
        conn.rollback()
        return False, f"å¯¼å…¥å¤±è´¥: {str(e)}"
    finally:
        conn.close()

# æ”¹è¿›çš„æ–‡æœ¬æ ‡å‡†åŒ–å‡½æ•°
def normalize_text(text):
    """æ ‡å‡†åŒ–æ–‡æœ¬ï¼Œå¤„ç†ä¸­è‹±æ–‡æ··åˆ"""
    if not text:
        return ""

    # åŸºæœ¬æ¸…ç†
    text = text.strip()

    # ç»Ÿä¸€ç©ºæ ¼
    text = ' '.join(text.split())

    # è½¬æ¢ä¸ºå°å†™ï¼ˆä»…é™è‹±æ–‡ï¼‰
    normalized = ""
    for char in text:
        if char.isalpha() and ord(char) < 128:  # è‹±æ–‡å­—ç¬¦
            normalized += char.lower()
        else:
            normalized += char

    # ç§»é™¤å¤šä½™æ ‡ç‚¹
    normalized = re.sub(r'[^\w\s\u4e00-\u9fff]', '', normalized)

    return normalized

# å¢å¼ºçš„æ¨¡ç³ŠæŸ¥è¯¢æ•°æ®åº“å‡½æ•°
def query_database_fuzzy(question, threshold=0.6):
    """
    å¢å¼ºçš„æ¨¡ç³ŠæŸ¥è¯¢æ•°æ®åº“å‡½æ•°ï¼Œæ”¯æŒä¸­è‹±æ–‡æ··åˆé¢˜ç›®åŒ¹é…
    """
    if not question or len(question) < 3:
        return "æœªæ‰¾åˆ°ç­”æ¡ˆ"

    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()

    try:
        # è·å–æ‰€æœ‰é—®é¢˜
        c.execute("SELECT question, answer FROM questions")
        all_questions = c.fetchall()

        if not all_questions:
            return "æœªæ‰¾åˆ°ç­”æ¡ˆ"

        # æ ‡å‡†åŒ–è¾“å…¥é—®é¢˜
        clean_question = clean_text(question)

        # æå–å…³é”®è¯
        question_keywords = extract_mixed_keywords(clean_question)

        best_match = None
        best_score = 0

        print(f"æ­£åœ¨åŒ¹é…é—®é¢˜: {clean_question}")
        print(f"æå–çš„å…³é”®è¯: {question_keywords}")

        for db_question, db_answer in all_questions:
            # æ ‡å‡†åŒ–æ•°æ®åº“é—®é¢˜
            clean_db_question = clean_text(db_question)
            db_keywords = extract_mixed_keywords(clean_db_question)

            # è®¡ç®—å¤šç§ç›¸ä¼¼åº¦å¾—åˆ†
            scores = []

            # 1. æ•´ä½“æ–‡æœ¬ç›¸ä¼¼åº¦ (æƒé‡40%)
            text_similarity = SequenceMatcher(None, clean_question, clean_db_question).ratio()
            scores.append(text_similarity * 0.4)

            # 2. å…³é”®è¯åŒ¹é…åº¦ (æƒé‡30%)
            keyword_score = 0
            if question_keywords and db_keywords:
                common_keywords = set(question_keywords) & set(db_keywords)
                total_keywords = set(question_keywords) | set(db_keywords)
                keyword_score = len(common_keywords) / len(total_keywords) if total_keywords else 0
            scores.append(keyword_score * 0.3)

            # 3. åŒ…å«å…³ç³»åŒ¹é… (æƒé‡20%)
            contain_score = 0
            if clean_question in clean_db_question:
                contain_score = 0.9
            elif clean_db_question in clean_question:
                contain_score = 0.8
            elif any(kw in clean_db_question for kw in question_keywords if len(kw) > 2):
                contain_score = 0.6
            scores.append(contain_score * 0.2)

            # 4. ç¼–è¾‘è·ç¦»ç›¸ä¼¼åº¦ (æƒé‡10%)
            edit_similarity = calculate_edit_similarity(clean_question, clean_db_question)
            scores.append(edit_similarity * 0.1)

            # ç»¼åˆå¾—åˆ†
            final_score = sum(scores)

            # ç‰¹æ®ŠåŠ åˆ†è§„åˆ™
            # å¦‚æœåŒ…å«ç›¸åŒçš„è‹±æ–‡å•è¯
            question_en = extract_english_words(clean_question)
            db_en = extract_english_words(clean_db_question)
            if question_en & db_en:
                final_score += 0.15
                print(f"è‹±æ–‡å•è¯åŒ¹é…åŠ åˆ†: {question_en & db_en}")

            # å¦‚æœåŒ…å«ç›¸åŒçš„æ•°å­—
            question_nums = extract_numbers(clean_question)
            db_nums = extract_numbers(clean_db_question)
            if question_nums & db_nums:
                final_score += 0.1
                print(f"æ•°å­—åŒ¹é…åŠ åˆ†: {question_nums & db_nums}")

            # å¦‚æœåŒ…å«ç›¸åŒçš„ä¸­æ–‡å…³é”®è¯
            question_cn = extract_chinese_words(clean_question)
            db_cn = extract_chinese_words(clean_db_question)
            common_cn = question_cn & db_cn
            if common_cn:
                final_score += len(common_cn) * 0.05
                print(f"ä¸­æ–‡å…³é”®è¯åŒ¹é…åŠ åˆ†: {common_cn}")

            # è®°å½•æœ€ä½³åŒ¹é…
            if final_score > best_score and final_score > threshold:
                best_score = final_score
                best_match = db_answer
                print(f"æ‰¾åˆ°æ›´å¥½çš„åŒ¹é…: {db_question} -> {db_answer} (å¾—åˆ†: {final_score:.3f})")

        result = best_match if best_match else "æœªæ‰¾åˆ°ç­”æ¡ˆ"
        print(f"æœ€ç»ˆåŒ¹é…ç»“æœ: {result} (æœ€é«˜å¾—åˆ†: {best_score:.3f})")
        return result

    except Exception as e:
        print(f"æ•°æ®åº“æŸ¥è¯¢é”™è¯¯: {e}")
        return "æœªæ‰¾åˆ°ç­”æ¡ˆ"
    finally:
        conn.close()

def clean_text(text):
    """æ¸…ç†å’Œæ ‡å‡†åŒ–æ–‡æœ¬"""
    if not text:
        return ""

    # ç»Ÿä¸€ç©ºæ ¼
    text = ' '.join(text.split())

    # è½¬æ¢è‹±æ–‡ä¸ºå°å†™ï¼Œä¿æŒä¸­æ–‡ä¸å˜
    result = ""
    for char in text:
        if char.isalpha() and ord(char) < 128:  # è‹±æ–‡å­—ç¬¦
            result += char.lower()
        else:
            result += char

    # ç§»é™¤å¤šä½™æ ‡ç‚¹ä½†ä¿ç•™åŸºæœ¬æ ‡ç‚¹
    result = re.sub(r'[^\w\s\u4e00-\u9fffï¼Ÿï¼ã€‚ï¼Œã€ï¼šï¼›]', '', result)

    return result.strip()

def extract_keywords(text):
    """
    æå–æ–‡æœ¬å…³é”®è¯ï¼Œæ”¯æŒä¸­è‹±æ–‡æ··åˆæ–‡æœ¬

    Args:
        text: è¾“å…¥çš„æ–‡æœ¬

    Returns:
        list: å…³é”®è¯åˆ—è¡¨
    """
    if not text or len(text) < 2:
        return []

    keywords = []

    # 1. æå–ä¸­æ–‡å…³é”®è¯
    try:
        # ä½¿ç”¨jiebaåˆ†è¯
        chinese_words = jieba.cut(text)
        for word in chinese_words:
            # è¿‡æ»¤æ‰åœç”¨è¯å’Œå•ä¸ªå­—ç¬¦
            if (len(word) > 1 and
                    re.match(r'[\u4e00-\u9fff]+', word) and
                    word not in ['çš„', 'æ˜¯', 'äº†', 'åœ¨', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'éƒ½', 'è¦',
                                 'å¯ä»¥', 'è¿™ä¸ª', 'é‚£ä¸ª', 'ä»€ä¹ˆ', 'å“ªé‡Œ', 'æ€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'å› ä¸º',
                                 'æ‰€ä»¥', 'ä½†æ˜¯', 'ç„¶å', 'å¦‚æœ', 'æˆ–è€…', 'è€Œä¸”', 'è¿˜æ˜¯', 'è™½ç„¶',
                                 'è™½ç„¶', 'æ— è®º', 'ä¸ç®¡', 'ä¸€äº›', 'è®¸å¤š', 'å¾ˆå¤š', 'éå¸¸', 'ç‰¹åˆ«',
                                 'æ¯”è¾ƒ', 'æ›´åŠ ', 'æœ€ä¸º', 'ååˆ†', 'ç›¸å½“', 'æå…¶', 'å®Œå…¨', 'å®Œæ•´',
                                 'ä¸»è¦', 'é‡è¦', 'å…³é”®', 'åŸºæœ¬', 'ç®€å•', 'å¤æ‚', 'å›°éš¾', 'å®¹æ˜“']):
                keywords.append(word)
    except Exception as e:
        print(f"ä¸­æ–‡åˆ†è¯é”™è¯¯: {e}")

    # 2. æå–è‹±æ–‡å•è¯
    english_words = re.findall(r'[a-zA-Z]+', text)
    for word in english_words:
        if (len(word) > 1 and
                word.lower() not in ['the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
                                     'of', 'with', 'by', 'from', 'up', 'about', 'into', 'through',
                                     'during', 'before', 'after', 'above', 'below', 'over', 'under',
                                     'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have',
                                     'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',
                                     'should', 'may', 'might', 'can', 'must', 'shall', 'this',
                                     'that', 'these', 'those', 'what', 'which', 'who', 'when',
                                     'where', 'why', 'how', 'very', 'much', 'many', 'most', 'more',
                                     'some', 'any', 'all', 'each', 'every', 'both', 'either', 'neither']):
            keywords.append(word.lower())

    # 3. æå–æ•°å­—
    numbers = re.findall(r'\d+', text)
    keywords.extend(numbers)

    # 4. æå–ç‰¹æ®Šç¬¦å·å’Œæ ‡ç‚¹ï¼ˆæŸäº›æƒ…å†µä¸‹å¯èƒ½é‡è¦ï¼‰
    special_chars = re.findall(r'[ï¼Ÿï¼ã€‚ï¼Œã€ï¼šï¼›""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹ã€ˆã€‰]', text)
    for char in special_chars:
        if char in ['ï¼Ÿ', 'ï¼', 'ã€‚']:  # åªä¿ç•™é‡è¦çš„æ ‡ç‚¹
            keywords.append(char)

    # 5. æå–ä¸“æœ‰åè¯ï¼ˆå¤§å†™å­—æ¯å¼€å¤´çš„è¯ï¼‰
    proper_nouns = re.findall(r'[A-Z][a-z]+', text)
    for noun in proper_nouns:
        if len(noun) > 1:
            keywords.append(noun.lower())

    # 6. æå–ç¼©å†™è¯
    abbreviations = re.findall(r'[A-Z]{2,}', text)
    for abbr in abbreviations:
        keywords.append(abbr.lower())

    # 7. å»é‡å¹¶ä¿æŒé¡ºåº
    seen = set()
    unique_keywords = []
    for keyword in keywords:
        if keyword not in seen:
            seen.add(keyword)
            unique_keywords.append(keyword)

    # 8. æŒ‰é•¿åº¦æ’åºï¼Œä¼˜å…ˆä¿ç•™è¾ƒé•¿çš„å…³é”®è¯
    unique_keywords.sort(key=len, reverse=True)

    return unique_keywords[:20]  # é™åˆ¶å…³é”®è¯æ•°é‡ï¼Œé¿å…è¿‡å¤š


def normalize_text(text):
    """
    æ ‡å‡†åŒ–æ–‡æœ¬ï¼Œé…åˆextract_keywordsä½¿ç”¨

    Args:
        text: è¾“å…¥æ–‡æœ¬

    Returns:
        str: æ ‡å‡†åŒ–åçš„æ–‡æœ¬
    """
    if not text:
        return ""

    # 1. ç»Ÿä¸€ç©ºæ ¼
    text = ' '.join(text.split())

    # 2. è½¬æ¢è‹±æ–‡ä¸ºå°å†™
    result = ""
    for char in text:
        if char.isalpha() and ord(char) < 128:  # è‹±æ–‡å­—ç¬¦
            result += char.lower()
        else:
            result += char

    # 3. ç»Ÿä¸€æ ‡ç‚¹ç¬¦å·
    punctuation_map = {
        'ï¼Ÿ': '?',
        'ï¼': '!',
        'ã€‚': '.',
        'ï¼Œ': ',',
        'ï¼š': ':',
        'ï¼›': ';',
        '"': '"',
        '"': '"',
        ''': "'",
        ''': "'",
        'ï¼ˆ': '(',
        'ï¼‰': ')',
        'ã€': '[',
        'ã€‘': ']',
        'ã€Š': '<',
        'ã€‹': '>',
        'ã€': ',',
    }

    for chinese_punct, english_punct in punctuation_map.items():
        result = result.replace(chinese_punct, english_punct)

    # 4. ç§»é™¤å¤šä½™çš„æ ‡ç‚¹å’Œç‰¹æ®Šå­—ç¬¦ï¼Œä½†ä¿ç•™åŸºæœ¬çš„
    result = re.sub(r'[^\w\s\u4e00-\u9fff?!.,;:()\[\]<>\'"-]', '', result)

    # 5. åˆå¹¶å¤šä¸ªç©ºæ ¼
    result = re.sub(r'\s+', ' ', result)

    return result.strip()

def extract_mixed_keywords(text):
    """æå–ä¸­è‹±æ–‡æ··åˆæ–‡æœ¬çš„å…³é”®è¯"""
    if not text:
        return []

    keywords = []

    # ä¸­æ–‡åˆ†è¯
    try:
        chinese_words = jieba.cut(text)
        for word in chinese_words:
            if len(word) > 1 and word not in ['çš„', 'æ˜¯', 'äº†', 'åœ¨', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'éƒ½', 'è¦', 'å¯ä»¥', 'è¿™ä¸ª', 'é‚£ä¸ª', 'ä»€ä¹ˆ', 'å“ªé‡Œ', 'æ€ä¹ˆ']:
                keywords.append(word)
    except:
        pass

    # è‹±æ–‡å•è¯æå–
    english_words = re.findall(r'[a-zA-Z]+', text)
    for word in english_words:
        if len(word) > 1:
            keywords.append(word.lower())

    # æ•°å­—æå–
    numbers = re.findall(r'\d+', text)
    keywords.extend(numbers)

    return list(set(keywords))

def extract_english_words(text):
    """æå–è‹±æ–‡å•è¯"""
    if not text:
        return set()

    words = re.findall(r'[a-zA-Z]+', text.lower())
    return set(word for word in words if len(word) > 1)

def extract_numbers(text):
    """æå–æ•°å­—"""
    if not text:
        return set()

    numbers = re.findall(r'\d+', text)
    return set(numbers)

def extract_chinese_words(text):
    """æå–ä¸­æ–‡å…³é”®è¯"""
    if not text:
        return set()

    try:
        words = jieba.cut(text)
        chinese_words = []
        for word in words:
            if len(word) > 1 and re.match(r'[\u4e00-\u9fff]+', word):
                if word not in ['çš„', 'æ˜¯', 'äº†', 'åœ¨', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'éƒ½', 'è¦', 'å¯ä»¥', 'è¿™ä¸ª', 'é‚£ä¸ª', 'ä»€ä¹ˆ', 'å“ªé‡Œ', 'æ€ä¹ˆ', 'ä¸ºä»€ä¹ˆ']:
                    chinese_words.append(word)
        return set(chinese_words)
    except:
        return set()

def calculate_edit_similarity(s1, s2):
    """è®¡ç®—ç¼–è¾‘è·ç¦»ç›¸ä¼¼åº¦"""
    if not s1 or not s2:
        return 0

    # ä½¿ç”¨ç®€å•çš„ç¼–è¾‘è·ç¦»ç®—æ³•
    m, n = len(s1), len(s2)
    dp = [[0] * (n + 1) for _ in range(m + 1)]

    for i in range(m + 1):
        dp[i][0] = i
    for j in range(n + 1):
        dp[0][j] = j

    for i in range(1, m + 1):
        for j in range(1, n + 1):
            if s1[i-1] == s2[j-1]:
                dp[i][j] = dp[i-1][j-1]
            else:
                dp[i][j] = 1 + min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1])

    max_len = max(m, n)
    return (max_len - dp[m][n]) / max_len if max_len > 0 else 0

# æ”¹è¿›çš„æ¨¡ç³ŠåŒ¹é…å‡½æ•°
def enhanced_fuzzy_match(question, threshold=0.6):
    """å¢å¼ºçš„æ¨¡ç³ŠåŒ¹é…ï¼Œæ”¯æŒä¸­è‹±æ–‡æ··åˆ"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()

    # è·å–æ‰€æœ‰é—®é¢˜
    c.execute("SELECT question, answer FROM questions")
    all_questions = c.fetchall()
    conn.close()

    if not all_questions:
        return "æœªæ‰¾åˆ°ç­”æ¡ˆ", 0

    # æ ‡å‡†åŒ–è¾“å…¥é—®é¢˜
    norm_question = normalize_text(question)
    question_keywords = extract_keywords(norm_question)

    best_match = None
    best_score = 0
    best_confidence = 0

    for db_question, db_answer in all_questions:
        # æ ‡å‡†åŒ–æ•°æ®åº“é—®é¢˜
        norm_db_question = normalize_text(db_question)
        db_keywords = extract_keywords(norm_db_question)

        # è®¡ç®—å¤šç§ç›¸ä¼¼åº¦
        scores = []

        # 1. æ•´ä½“æ–‡æœ¬ç›¸ä¼¼åº¦
        text_similarity = SequenceMatcher(None, norm_question, norm_db_question).ratio()
        scores.append(text_similarity * 0.4)

        # 2. å…³é”®è¯åŒ¹é…åº¦
        if question_keywords and db_keywords:
            common_keywords = set(question_keywords) & set(db_keywords)
            keyword_score = len(common_keywords) / len(set(question_keywords) | set(db_keywords))
            scores.append(keyword_score * 0.3)

        # 3. åŒ…å«å…³ç³»åŒ¹é…
        contain_score = 0
        if norm_question in norm_db_question or norm_db_question in norm_question:
            contain_score = 0.8
        scores.append(contain_score * 0.2)

        # 4. ç¼–è¾‘è·ç¦»ç›¸ä¼¼åº¦
        import difflib
        edit_similarity = difflib.SequenceMatcher(None, norm_question, norm_db_question).ratio()
        scores.append(edit_similarity * 0.1)

        # ç»¼åˆå¾—åˆ†
        final_score = sum(scores)

        # ç‰¹æ®ŠåŠ åˆ†ï¼šå¦‚æœåŒ…å«ç›¸åŒçš„è‹±æ–‡å•è¯æˆ–æ•°å­—
        question_en = set(re.findall(r'[a-zA-Z]+', norm_question.lower()))
        db_en = set(re.findall(r'[a-zA-Z]+', norm_db_question.lower()))
        if question_en & db_en:
            final_score += 0.15

        question_nums = set(re.findall(r'\d+', norm_question))
        db_nums = set(re.findall(r'\d+', norm_db_question))
        if question_nums & db_nums:
            final_score += 0.1

        if final_score > best_score and final_score > threshold:
            best_score = final_score
            best_match = db_answer
            best_confidence = int(final_score * 100)

    return best_match if best_match else "æœªæ‰¾åˆ°ç­”æ¡ˆ", best_confidence

def split_questions(text):
    """å¢å¼ºçš„é—®é¢˜åˆ†å‰²å‡½æ•°ï¼Œæ”¯æŒå˜å½¢åºå·"""
    if not text or len(text) < 5:
        return []

    # é¢„å¤„ç†ï¼šæ¸…ç†OCRå™ªå£°ï¼ˆå¦‚å°†"1è†"ä¿®æ­£ä¸º"1."ï¼‰
    cleaned_text = re.sub(r'(\d+)[^\d\s\.\ã€]', r'\1. ', text)  # æ•°å­—åæ¥éåˆ†éš”ç¬¦â†’æ•°å­—+.
    cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()

    # åˆ†å‰²ç­–ç•¥1ï¼šåŒ¹é…æ•°å­—+åˆ†éš”ç¬¦ï¼ˆæ”¯æŒå˜å½¢å¦‚"1è†"â†’"1."ï¼‰
    pattern = r'(\d+[\.\ã€\s]\s*[^\d]+?)(?=\d+[\.\ã€\s]|$)'
    matches = re.findall(pattern, cleaned_text, re.DOTALL)
    questions = [match.strip() for match in matches if len(match) > 5]

    # åˆ†å‰²ç­–ç•¥2ï¼šæŒ‰é—®å·åˆ†å‰²ï¼ˆè‹¥æ— åºå·ï¼‰
    if not questions:
        questions = [q.strip() + '?' for q in cleaned_text.split('?') if q.strip()]

    # åˆ†å‰²ç­–ç•¥3ï¼šæŒ‰æ¢è¡Œåˆ†å‰²
    if not questions:
        questions = [line.strip() for line in cleaned_text.split('\n') if len(line) > 8]

    print(f"åˆ†å‰²ç»“æœ: {questions}")  # è°ƒè¯•ç”¨
    return questions[:5]  # æœ€å¤šè¿”å›5ä¸ªé—®é¢˜

# é—®é¢˜åˆ†å‰²å’Œæ¸…ç†å‡½æ•°
def split_and_clean_questions(text):
    """åˆ†å‰²å’Œæ¸…ç†é—®é¢˜æ–‡æœ¬"""
    if not text or len(text) < 5:
        return []

    # æ¸…ç†æ–‡æœ¬
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()

    questions = []

    # åˆ†å‰²ç­–ç•¥
    patterns = [
        r'(\d+[\.\ã€]\s*[^\d\.\ã€]+?)(?=\d+[\.\ã€]|$)',  # æ•°å­—ç¼–å·
        r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[\ã€\.].*?)(?=[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[\ã€\.]|$)',  # ä¸­æ–‡ç¼–å·
        r'([A-Z][\.\)]\s*[^A-Z\.\)]+?)(?=[A-Z][\.\)]|$)',  # è‹±æ–‡ç¼–å·
    ]

    for pattern in patterns:
        matches = re.findall(pattern, text, re.DOTALL)
        if matches and len(matches) > 1:
            questions.extend([match.strip() for match in matches])
            break

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ†å‰²æ¨¡å¼ï¼ŒæŒ‰é—®å·åˆ†å‰²
    if not questions:
        parts = text.split('ï¼Ÿ')
        questions = [part.strip() + 'ï¼Ÿ' for part in parts if part.strip()]

    # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼ŒæŒ‰å¥å·åˆ†å‰²
    if not questions:
        parts = text.split('ã€‚')
        questions = [part.strip() + 'ã€‚' for part in parts if part.strip() and len(part.strip()) > 8]

    # æœ€åå°è¯•æŒ‰é•¿åº¦åˆ†å‰²
    if not questions and len(text) > 50:
        # æŒ‰ç…§åˆç†é•¿åº¦åˆ†å‰²
        words = text.split()
        chunk_size = 15
        for i in range(0, len(words), chunk_size):
            chunk = ' '.join(words[i:i+chunk_size])
            if len(chunk) > 10:
                questions.append(chunk)

    # å¦‚æœéƒ½æ²¡æœ‰æˆåŠŸï¼Œè¿”å›åŸæ–‡æœ¬
    if not questions:
        questions = [text]

    # è¿‡æ»¤å’Œæ¸…ç†
    cleaned_questions = []
    for q in questions:
        q = q.strip()
        if len(q) > 8 and len(q) < 500:  # åˆç†é•¿åº¦èŒƒå›´
            cleaned_questions.append(q)

    return cleaned_questions[:5]  # æœ€å¤šè¿”å›5ä¸ªé—®é¢˜

# å›¾åƒé¢„å¤„ç†å‡½æ•°
def preprocess_image(image):
    """ä¼˜åŒ–çš„å›¾åƒé¢„å¤„ç†"""
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image

    # å¯¹æ¯”åº¦å¢å¼º
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    gray = clahe.apply(gray)

    # é™å™ª
    gray = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)

    # è‡ªé€‚åº”é˜ˆå€¼
    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                  cv2.THRESH_BINARY, 11, 2)

    # å½¢æ€å­¦æ“ä½œ
    kernel = np.ones((1, 1), np.uint8)
    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)

    # é”åŒ–
    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
    binary = cv2.filter2D(binary, -1, kernel)

    return binary

# å¢å¼ºçš„OCRå‡½æ•°
def enhanced_ocr(image):
    """å¢å¼ºçš„OCRè¯†åˆ«"""
    try:
        # å¤šç§é…ç½®å°è¯•
        configs = [
            '--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ.,?!:;()[]{}<>/\\\'"@#$%^&*_-+= \u4e00-\u9fff',
            '--oem 3 --psm 11',
            '--oem 3 --psm 12',
            '--oem 3 --psm 4',
        ]

        best_text = ""
        for config in configs:
            try:
                text = pytesseract.image_to_string(
                    image,
                    lang='chi_sim+eng',
                    config=config
                ).strip()

                if len(text) > len(best_text):
                    best_text = text
            except:
                continue

        # åå¤„ç†ï¼šä¿®æ­£å¸¸è§OCRé”™è¯¯
        corrections = {
            'wikere': 'where',
            'Cirimal': 'China',
            'SEE': 'sgg',
            'meme': 'name',
            'ont': 'cctv',
            'ILA': 'ä¸­æ–‡å'
        }

        for wrong, right in corrections.items():
            best_text = best_text.replace(wrong, right)

        return best_text

    except Exception as e:
        print(f"OCRè¯†åˆ«é”™è¯¯: {e}")
        return ""

# ä¸»è¦çš„è§†é¢‘å¤„ç†å‡½æ•°
def process_video_stream():
    """ä¸»è¦çš„è§†é¢‘å¤„ç†å‡½æ•°"""
    global current_qa_pairs, last_qa_pairs, last_update_time, frame_counter, is_running

    # æ‰“å¼€è§†é¢‘æº
    cap = None
    video_sources = [0, 1, 2, "/dev/video0", "/dev/video1", "/dev/video2"]

    for source in video_sources:
        try:
            cap = cv2.VideoCapture(source)
            if cap.isOpened():
                print(f"æˆåŠŸæ‰“å¼€è§†é¢‘æº: {source}")
                break
        except:
            continue

    if not cap or not cap.isOpened():
        print("æ— æ³•æ‰“å¼€è§†é¢‘æº")
        is_running = False
        return

    # è®¾ç½®è§†é¢‘å‚æ•°
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    cap.set(cv2.CAP_PROP_FPS, 30)

    print("å¼€å§‹è§†é¢‘å¤„ç†...")

    while is_running:
        ret, frame = cap.read()
        if not ret:
            time.sleep(0.1)
            continue

        frame_counter += 1

        # å®šæœŸå¤„ç†
        if frame_counter % process_interval == 0:
            try:
                # è°ƒæ•´ROIåŒºåŸŸ
                height, width = frame.shape[:2]
                roi = frame[int(height*0.1):int(height*0.9), int(width*0.1):int(width*0.9)]

                # æ—‹è½¬æ ¡æ­£ (å¦‚æœè§†é¢‘æºéœ€è¦)
                # roi = cv2.rotate(roi, cv2.ROTATE_90_CLOCKWISE)

                # é¢„å¤„ç†
                processed_image = preprocess_image(roi)

                # ä¿å­˜è°ƒè¯•å›¾åƒ
                cv2.imwrite('debug_processed.png', processed_image)

                # OCRè¯†åˆ«
                text = enhanced_ocr(processed_image)

                if text and len(text) > 10:
                    current_ocr_text = text
    # åˆ†å‰²é—®é¢˜
                    questions = split_questions(text)

                    if questions:

        # ä¸éœ€è¦è¿›è¡Œç›¸ä¼¼åº¦æ¯”è¾ƒï¼Œç›´æ¥å¤„ç†æ‰€æœ‰é—®é¢˜
                        qa_pairs = []

                        for question in questions:
                            if question and len(question) > 5:
                                answer = query_database_fuzzy(question)
                                qa_pairs.append({
                                    'question': question,
                                    'answer': answer,
                                    'confidence': None
                                })

                        current_qa_pairs = qa_pairs
                        last_update_time = datetime.now()

                        print(f"è¯†åˆ«åˆ° {len(questions)} ä¸ªé—®é¢˜")
                        for i, pair in enumerate(qa_pairs):
                            print(f"é—®é¢˜{i+1}: {pair['question'][:50]}...")
                            print(f"ç­”æ¡ˆ{i+1}: {pair['answer'][:50]}...")
                            if pair['confidence']:
                                print(f"åŒ¹é…åº¦: {pair['confidence']}%")
                                print("-" * 40)

            except Exception as e:
                print(f"å¤„ç†é”™è¯¯: {e}")

        time.sleep(0.05)

    cap.release()
    print("è§†é¢‘å¤„ç†å·²åœæ­¢")

# é—®é¢˜ç›¸ä¼¼åº¦æ¯”è¾ƒ
def are_qa_pairs_similar(questions1, questions2, threshold=0.8):
    """æ¯”è¾ƒä¸¤ç»„é—®é¢˜æ˜¯å¦ç›¸ä¼¼"""
    if len(questions1) != len(questions2):
        return False

    if not questions1 or not questions2:
        return False

    for q1, q2 in zip(questions1, questions2):
        similarity = SequenceMatcher(None, q1, q2).ratio()
        if similarity < threshold:
            return False

    return True



# å¯åŠ¨FlaskæœåŠ¡å™¨
def start_flask_server():
    app.run(host='0.0.0.0', port=5000, debug=False, use_reloader=False)

# ä¸»å‡½æ•°
def main():
    global is_running

    # ç¡®ä¿æ•°æ®åº“ç›®å½•å­˜åœ¨
    db_dir = os.path.dirname(DB_PATH)
    if not os.path.exists(db_dir):
        os.makedirs(db_dir)

    # # å¯¼å…¥é¢˜åº“
    # csv_path = 'questions.csv'
    # if os.path.exists(csv_path):
    #     print("æ­£åœ¨å¯¼å…¥é¢˜åº“...")
    #     import_question_bank(csv_path)
    # else:
    #     print(f"è­¦å‘Š: é¢˜åº“æ–‡ä»¶ {csv_path} ä¸å­˜åœ¨")

    # å¯åŠ¨FlaskæœåŠ¡å™¨
    flask_thread = threading.Thread(target=start_flask_server)
    flask_thread.daemon = True
    flask_thread.start()

    print("=" * 60)
    print("ä¼˜åŒ–ç‰ˆæ™ºèƒ½ç­”é¢˜ç³»ç»Ÿå·²å¯åŠ¨")
    print("Webç•Œé¢: http://localhost:5000")
    print("æ”¯æŒä¸­è‹±æ–‡æ··åˆé¢˜ç›®è¯†åˆ«ä¸åŒ¹é…")
    print("=" * 60)

    # è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨
    time.sleep(2)
    try:
        subprocess.run(['xdg-open', 'http://localhost:5000'])
    except:
        print("è¯·æ‰‹åŠ¨æ‰“å¼€æµè§ˆå™¨è®¿é—®: http://localhost:5000")

    # ä¿æŒè¿è¡Œ
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        print("\nç¨‹åºé€€å‡º")
        is_running = False

if __name__ == "__main__":
    main()
