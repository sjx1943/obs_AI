# Tasks - TODO

## In Progress
## 应用服务启动与知识库集成 (2025-11-10)

- [ ] **任务5.1**: 修复应用启动失败问题（ModuleNotFoundError: No module named 'assistant'）
- [ ] **任务5.2**: 解决知识库文档上传目录问题，确保文档能正确处理并索引
- [ ] **任务5.3**: 验证RAG流程中知识库检索功能的完整性和准确性

## To Do

- [ ] **微服务架构设计**: 将现有功能拆分为独立的微服务
  - [ ] 设计LLM服务模块
  - [ ] 设计RAG检索服务模块
  - [ ] 设计OBS录屏服务模块
  - [ ] 设计知识库管理服务模块
  - [ ] 设计试题解析服务模块

- [ ] **CLI菜单界面开发**: 实现命令行方式访问系统功能
  - [ ] 设计CLI交互界面
  - [ ] 实现菜单选择功能
  - [ ] 集成各服务模块到CLI界面

- [ ] **"投票"答复机制实现**: 开发多个模型投票选择最佳回复的功能
  - [ ] 设计模型群组管理机制
  - [ ] 实现投票算法
  - [ ] 集成到现有问答流程中

- [ ] **音频I/O组件集成**: 添加音频输入输出功能
  - [ ] 集成语音识别组件
  - [ ] 集成文本转语音组件
  - [ ] 实现音频问答功能

- [ ] **微调功能开发**: 实现模型微调功能
  - [ ] 设计微调接口
  - [ ] 实现微调训练流程
  - [ ] 集成微调模型到服务中

## Backlog

## 视频分析功能优化 (2025-10-11)

- [x] **任务1.1**: 增强 `video_processing.py` 中的OCR文本处理能力，提高对复杂场景的适应性。
- [x] **任务1.2**: 优化 `parse_ocr_text_to_qa` 函数，使其能正确提取问答对。
- [x] **任务1.3**: 增加对OCR结果的后处理，提高文本质量。

## 视频分析问答流程修复 (2025-10-15)

- [x] **任务2.1**: 设计并实现一个强制LLM返回JSON格式的新Prompt。
- [x] **任务2.2**: 在RAG流程中为视频问答增加专门处理分支，调用新Prompt。
- [x] **任务2.3**: 确保返回给前端的 `AskResponse` 数据模型字段完整，修复 `undefined` 问题。

## 统一前端答案展示格式 (2025-10-18)

- [x] **任务3.1**: 设计前端展示格式，按照"题号 + 答案 + 理由（知识库片段）"的格式展示分析结果。
- [x] **任务3.2**: 实现展示格式化函数，确保所有答案按统一格式呈现。
- [x] **任务3.3**: 验证前端展示效果，确保信息完整性和可读性。

## 视频分析功能调试 (2025-10-17)

- [x] **任务4.1**: 深入调试视频分析流程，验证OCR结果、Q&A提取及RAG问答的准确性。
- [x] **任务4.2**: 优化 `video_processing.py` 中的 `parse_ocr_text_to_qa` 函数，提高对复杂场景的适应性。
- [x] **任务4.3**: 收集并分析失败案例，建立测试用例集。



## Done

- [x] **环境准备**: 完成MacOS M4环境下的Ollama安装
- [x] **模型下载**: 下载qwen2.5:3b模型并更新环境配置

- [x] **环境搭建与迁移**: 将项目从Ubuntu环境迁移到MacOS M4芯片环境
    - [x] 安装并配置Ollama服务以支持本地LLM运行
    - [x] 验证所有Python依赖在MacOS上的兼容性
    - [x] 更新项目配置以适配MacOS环境