# LLM 学习助手开发日志

## 2025-06-25

1. 发现并解决了模型连接问题，原因是测试脚本中使用的模型名称与Ollama中实际存在的模型名称不匹配
2. 修复了模型对比测试脚本，使用正确的模型名称，包括qwen2.5:3b、qwen2.5:3b-instruct-q4_0等
3. 修复了RAG参数调整测试脚本中的错误处理逻辑，避免当所有配置准确率为0时出现TypeError
4. 运行了模型对比测试和RAG参数调整测试，确定了最佳模型组合：llama3.2:3b-instruct-q4_0与优化后RAGPipeline，准确率达37.50%
5. 根据测试结果更新了系统配置，将模型从qwen2.5:3b-instruct-q4_0更换为llama3.2:3b-instruct-q4_0，并优化了RAG参数(TOP_K=3, CHUNK_SIZE=250, CHUNK_OVERLAP=50)
6. 创建了配置验证脚本和问答能力测试脚本，验证了新配置能够正常工作并回答问题
7. 编写了详细的测试结果分析报告和模型连接问题解决报告，记录了所有变更和后续优化建议

## 2025-11-10

1. 发现并诊断了应用服务启动失败问题，错误为 `ModuleNotFoundError: No module named 'assistant'`
2. 检查了知识库文档上传目录问题，发现上传目录未正确创建且文档未被处理
3. 尝试启动应用服务但失败，确定需要修复模块导入问题
4. 更新了TODO.md文件，添加了关于应用启动和知识库集成的任务项
5. 更新了GEMINI.md文件，反映了当前项目状态

## 2025-11-12

1. 完成了Ollama安装配置
2. 完成了Python虚拟环境配置
3. 完成了环境变量设置
4. 完成了环境验证

## 2025-10-18

1. 设计了前端展示格式，按照"题号 + 答案 + 理由（知识库片段）"的格式展示分析结果
2. 实现了展示格式化函数，确保所有答案按统一格式呈现
3. 验证了前端展示效果，确保信息完整性和可读性

## 2025-10-17

1. 深入调试了视频分析流程，验证了OCR结果、Q&A提取及RAG问答的准确性
2. 优化了 `video_processing.py` 中的 `parse_ocr_text_to_qa` 函数，提高了对复杂场景的适应性
3. 收集并分析了失败案例，建立了测试用例集

## 2025-10-15

1. 设计并实现了一个强制LLM返回JSON格式的新Prompt
2. 在RAG流程中为视频问答增加了专门处理分支，调用新Prompt
3. 确保了返回给前端的 `AskResponse` 数据模型字段完整，修复了 `undefined` 问题

## 2025-10-11

1. 增强了 `video_processing.py` 中的OCR文本处理能力，提高了对复杂场景的适应性
2. 优化了 `parse_ocr_text_to_qa` 函数，使其能正确提取问答对
3. 增加了对OCR结果的后处理，提高了文本质量